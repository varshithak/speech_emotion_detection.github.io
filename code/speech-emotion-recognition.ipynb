{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import glob \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "TESS = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
    "RAV = \"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24/\"\n",
    "SAVEE = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"\n",
    "CREMA = \"/kaggle/input/cremad/AudioWAV/\"\n",
    "\n",
    "# Run one example \n",
    "dir_list = os.listdir(SAVEE)\n",
    "dir_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data location for SAVEE\n",
    "dir_list = os.listdir(SAVEE)\n",
    "\n",
    "# parse the filename to get the emotions\n",
    "emotion=[]\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    if i[-8:-6]=='_a':\n",
    "        emotion.append('male_angry')\n",
    "    elif i[-8:-6]=='_d':\n",
    "        emotion.append('male_disgust')\n",
    "    elif i[-8:-6]=='_f':\n",
    "        emotion.append('male_fear')\n",
    "    elif i[-8:-6]=='_h':\n",
    "        emotion.append('male_happy')\n",
    "    elif i[-8:-6]=='_n':\n",
    "        emotion.append('male_neutral')\n",
    "    elif i[-8:-6]=='sa':\n",
    "        emotion.append('male_sad')\n",
    "    elif i[-8:-6]=='su':\n",
    "        emotion.append('male_surprise')\n",
    "    else:\n",
    "        emotion.append('male_error') \n",
    "    path.append(SAVEE + i)\n",
    "\n",
    "# Now check out the label count distribution \n",
    "SAVEE_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "SAVEE_df['source'] = 'SAVEE'\n",
    "SAVEE_df = pd.concat([SAVEE_df, pd.DataFrame(path, columns = ['path'])], axis = 1)\n",
    "SAVEE_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the well known Librosa library for this task \n",
    "fname = SAVEE + 'DC_f11.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets play a happy track\n",
    "fname = SAVEE + 'DC_h11.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(RAV)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(RAV + i)\n",
    "    for f in fname:\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        temp = int(part[6])\n",
    "        if temp%2 == 0:\n",
    "            temp = \"female\"\n",
    "        else:\n",
    "            temp = \"male\"\n",
    "        gender.append(temp)\n",
    "        path.append(RAV + i + '/' + f)\n",
    "\n",
    "        \n",
    "RAV_df = pd.DataFrame(emotion)\n",
    "RAV_df = RAV_df.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "RAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\n",
    "RAV_df.columns = ['gender','emotion']\n",
    "RAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\n",
    "RAV_df['source'] = 'RAVDESS'  \n",
    "RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\n",
    "RAV_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a fearful track\n",
    "fname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a happy track\n",
    "fname = RAV + 'Actor_14/03-01-03-02-02-02-14.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(TESS)\n",
    "dir_list.sort()\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "emotion = []\n",
    "\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(TESS + i)\n",
    "    for f in fname:\n",
    "        if i == 'OAF_angry' or i == 'YAF_angry':\n",
    "            emotion.append('female_angry')\n",
    "        elif i == 'OAF_disgust' or i == 'YAF_disgust':\n",
    "            emotion.append('female_disgust')\n",
    "        elif i == 'OAF_Fear' or i == 'YAF_fear':\n",
    "            emotion.append('female_fear')\n",
    "        elif i == 'OAF_happy' or i == 'YAF_happy':\n",
    "            emotion.append('female_happy')\n",
    "        elif i == 'OAF_neutral' or i == 'YAF_neutral':\n",
    "            emotion.append('female_neutral')                                \n",
    "        elif i == 'OAF_Pleasant_surprise' or i == 'YAF_pleasant_surprised':\n",
    "            emotion.append('female_surprise')               \n",
    "        elif i == 'OAF_Sad' or i == 'YAF_sad':\n",
    "            emotion.append('female_sad')\n",
    "        else:\n",
    "            emotion.append('Unknown')\n",
    "        path.append(TESS + i + \"/\" + f)\n",
    "\n",
    "TESS_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "TESS_df['source'] = 'TESS'\n",
    "TESS_df = pd.concat([TESS_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "TESS_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets play a fearful track \n",
    "fname = TESS + 'YAF_fear/YAF_dog_fear.wav' \n",
    "\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets play a happy track \n",
    "fname =  TESS + 'YAF_happy/YAF_dog_happy.wav' \n",
    "\n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(CREMA)\n",
    "dir_list.sort()\n",
    "print(dir_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = []\n",
    "emotion = []\n",
    "path = []\n",
    "female = [1002,1003,1004,1006,1007,1008,1009,1010,1012,1013,1018,1020,1021,1024,1025,1028,1029,1030,1037,1043,1046,1047,1049,\n",
    "          1052,1053,1054,1055,1056,1058,1060,1061,1063,1072,1073,1074,1075,1076,1078,1079,1082,1084,1089,1091]\n",
    "\n",
    "for i in dir_list: \n",
    "    part = i.split('_')\n",
    "    if int(part[0]) in female:\n",
    "        temp = 'female'\n",
    "    else:\n",
    "        temp = 'male'\n",
    "    gender.append(temp)\n",
    "    if part[2] == 'SAD' and temp == 'male':\n",
    "        emotion.append('male_sad')\n",
    "    elif part[2] == 'ANG' and temp == 'male':\n",
    "        emotion.append('male_angry')\n",
    "    elif part[2] == 'DIS' and temp == 'male':\n",
    "        emotion.append('male_disgust')\n",
    "    elif part[2] == 'FEA' and temp == 'male':\n",
    "        emotion.append('male_fear')\n",
    "    elif part[2] == 'HAP' and temp == 'male':\n",
    "        emotion.append('male_happy')\n",
    "    elif part[2] == 'NEU' and temp == 'male':\n",
    "        emotion.append('male_neutral')\n",
    "    elif part[2] == 'SAD' and temp == 'female':\n",
    "        emotion.append('female_sad')\n",
    "    elif part[2] == 'ANG' and temp == 'female':\n",
    "        emotion.append('female_angry')\n",
    "    elif part[2] == 'DIS' and temp == 'female':\n",
    "        emotion.append('female_disgust')\n",
    "    elif part[2] == 'FEA' and temp == 'female':\n",
    "        emotion.append('female_fear')\n",
    "    elif part[2] == 'HAP' and temp == 'female':\n",
    "        emotion.append('female_happy')\n",
    "    elif part[2] == 'NEU' and temp == 'female':\n",
    "        emotion.append('female_neutral')\n",
    "    else:\n",
    "        emotion.append('Unknown')\n",
    "    path.append(CREMA + i)\n",
    "    \n",
    "CREMA_df = pd.DataFrame(emotion, columns = ['labels'])\n",
    "CREMA_df['source'] = 'CREMA'\n",
    "CREMA_df = pd.concat([CREMA_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "CREMA_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the well known Librosa library for this task \n",
    "fname = CREMA + '1012_IEO_HAP_HI.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fearful track\n",
    "fname = CREMA + '1012_IEO_FEA_HI.wav'  \n",
    "data, sampling_rate = librosa.load(fname)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)\n",
    "\n",
    "# Lets play the audio \n",
    "ipd.Audio(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([SAVEE_df, RAV_df, TESS_df, CREMA_df], axis = 0)\n",
    "print(df.labels.value_counts())\n",
    "df.head()\n",
    "df.to_csv(\"Data_path.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
